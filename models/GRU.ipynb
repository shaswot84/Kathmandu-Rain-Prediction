{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZU6L6qL4nQG-De_sdDvl33lQYOkGL9AY","authorship_tag":"ABX9TyNlpSPv/XwhdEm7c0/iZ4ij"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uq_iTgbBRHX8"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from torch.utils.data import DataLoader, Dataset\n","from itertools import product"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/Kathmandu-Precipitation/data/Outlier-removed-dataset.csv\")\n","features = [ i for i in df.columns if i not in [\"precipitation\",\"datetime\"]]\n","target = [\"precipitation\"]\n","X = df[features]\n","y = df[target]"],"metadata":{"id":"_UJCDa_3RTSP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xIsYV5kcRXjb","executionInfo":{"status":"ok","timestamp":1752335063326,"user_tz":-345,"elapsed":8,"user":{"displayName":"Shaswot Poudyal","userId":"10950154078121976776"}},"outputId":"ddb43546-86d9-443d-e01f-1bbf43e46052"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1707, 7)\n","(1707, 1)\n"]}]},{"cell_type":"code","source":["scaler_features = StandardScaler()\n","scaler_target = StandardScaler()\n","features_scaled = scaler_features.fit_transform(X)\n","target_scaled = scaler_target.fit_transform(y).flatten()"],"metadata":{"id":"QjJKnFnmRjUb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create sequences for GRU\n","def create_sequences(data, target, seq_length):\n","    xs, ys = [], []\n","    for i in range(len(data) - seq_length):\n","        x = data[i:i + seq_length]\n","        y = target[i + seq_length]\n","        xs.append(x)\n","        ys.append(y)\n","    return np.array(xs), np.array(ys)\n","\n","seq_length = 10  # Number of time steps in each sequence\n","X, y = create_sequences(features_scaled, target_scaled, seq_length)"],"metadata":{"id":"p6XzcZVwRlwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split into training, validation, and testing sets (rolling window)\n","train_size = int(len(X) * 0.7)\n","val_size = int(len(X) * 0.15)\n","test_size = len(X) - train_size - val_size\n","\n","X_train, X_val, X_test = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\n","y_train, y_val, y_test = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n","\n","# Convert to PyTorch tensors\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.float32)\n","X_val = torch.tensor(X_val, dtype=torch.float32)\n","y_val = torch.tensor(y_val, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)"],"metadata":{"id":"uwuYIc_WRn6r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_length = 10  # Number of time steps in each sequence\n","X, y = create_sequences(features_scaled, target_scaled, seq_length)\n","\n","# Split into training and testing sets (rolling window)\n","train_size = int(len(X) * 0.8)\n","test_size = len(X) - train_size\n","\n","X_train_full, X_test = X[:train_size], X[train_size:]\n","y_train_full, y_test = y[:train_size], y[train_size:]\n","\n","# Convert to PyTorch tensors\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)"],"metadata":{"id":"lbC3r5xVT5kE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(GRUModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # GRU layer\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","\n","        # Fully connected layer\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        # Initialize hidden state\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","\n","        # Forward propagate GRU\n","        out, _ = self.gru(x, h0)\n","\n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out"],"metadata":{"id":"aEqFGJCvRsEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyperparameter grid\n","param_grid = {\n","    'hidden_size': [32, 64, 128],\n","    'num_layers': [1, 2],\n","    'learning_rate': [0.001, 0.01],\n","    'batch_size': [16, 32]\n","}\n","\n","best_rmse = float('inf')\n","best_params = None\n","\n","for params in product(*param_grid.values()):\n","    hidden_size, num_layers, learning_rate, batch_size = params\n","\n","    # Instantiate the model\n","    model = GRUModel(\n","        input_size=7,\n","        hidden_size=hidden_size,\n","        num_layers=num_layers,\n","        output_size=1\n","    )\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training loop\n","    num_epochs = 20\n","    train_data = torch.utils.data.TensorDataset(X_train, y_train)\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for inputs, targets in train_loader:\n","            outputs = model(inputs)\n","            loss = criterion(outputs.squeeze(), targets)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","    # Evaluate on validation set\n","    model.eval()\n","    with torch.no_grad():\n","        val_predictions = model(X_val).squeeze().numpy()\n","        val_predictions_rescaled = scaler_target.inverse_transform(val_predictions.reshape(-1, 1)).flatten()\n","        y_val_rescaled = scaler_target.inverse_transform(y_val.numpy().reshape(-1, 1)).flatten()\n","\n","        val_rmse = np.sqrt(mean_squared_error(y_val_rescaled, val_predictions_rescaled))\n","\n","    print(f\"Params: {params}, Validation RMSE: {val_rmse:.4f}\")\n","\n","    # Save best parameters\n","    if val_rmse < best_rmse:\n","        best_rmse = val_rmse\n","        best_params = params\n","\n","print(f\"Best Params: {best_params}, Best Validation RMSE: {best_rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcgBOnm4RvsC","executionInfo":{"status":"ok","timestamp":1752829145770,"user_tz":-345,"elapsed":206508,"user":{"displayName":"Shaswot Poudyal","userId":"10950154078121976776"}},"outputId":"d6d353c8-8a3d-4733-d318-672cd2096453"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Params: (32, 1, 0.001, 16), Validation RMSE: 4.7928\n","Params: (32, 1, 0.001, 32), Validation RMSE: 4.7304\n","Params: (32, 1, 0.01, 16), Validation RMSE: 5.1396\n","Params: (32, 1, 0.01, 32), Validation RMSE: 5.4496\n","Params: (32, 2, 0.001, 16), Validation RMSE: 4.9356\n","Params: (32, 2, 0.001, 32), Validation RMSE: 4.8307\n","Params: (32, 2, 0.01, 16), Validation RMSE: 5.4276\n","Params: (32, 2, 0.01, 32), Validation RMSE: 5.3561\n","Params: (64, 1, 0.001, 16), Validation RMSE: 5.0024\n","Params: (64, 1, 0.001, 32), Validation RMSE: 4.9233\n","Params: (64, 1, 0.01, 16), Validation RMSE: 5.3268\n","Params: (64, 1, 0.01, 32), Validation RMSE: 5.3675\n","Params: (64, 2, 0.001, 16), Validation RMSE: 5.1317\n","Params: (64, 2, 0.001, 32), Validation RMSE: 4.9618\n","Params: (64, 2, 0.01, 16), Validation RMSE: 5.1444\n","Params: (64, 2, 0.01, 32), Validation RMSE: 5.1062\n","Params: (128, 1, 0.001, 16), Validation RMSE: 5.0865\n","Params: (128, 1, 0.001, 32), Validation RMSE: 5.0622\n","Params: (128, 1, 0.01, 16), Validation RMSE: 5.1563\n","Params: (128, 1, 0.01, 32), Validation RMSE: 5.1723\n","Params: (128, 2, 0.001, 16), Validation RMSE: 5.7318\n","Params: (128, 2, 0.001, 32), Validation RMSE: 5.1553\n","Params: (128, 2, 0.01, 16), Validation RMSE: 4.9176\n","Params: (128, 2, 0.01, 32), Validation RMSE: 4.8184\n","Best Params: (32, 1, 0.001, 32), Best Validation RMSE: 4.7304\n"]}]},{"cell_type":"code","source":["# Retrain with best parameters\n","hidden_size, num_layers, learning_rate, batch_size = best_params\n","model = GRUModel(\n","    input_size=7,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    output_size=1\n",")\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Combine training and validation sets\n","X_train_full = torch.cat((X_train, X_val), dim=0)\n","y_train_full = torch.cat((y_train, y_val), dim=0)\n","train_data = torch.utils.data.TensorDataset(X_train_full, y_train_full)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, targets in train_loader:\n","        outputs = model(inputs)\n","        loss = criterion(outputs.squeeze(), targets)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader):.4f}\")\n","\n","# Evaluate on test set\n","model.eval()\n","with torch.no_grad():\n","    test_predictions = model(X_test).squeeze().numpy()\n","    test_predictions_rescaled = scaler_target.inverse_transform(test_predictions.reshape(-1, 1)).flatten()\n","    y_test_rescaled = scaler_target.inverse_transform(y_test.numpy().reshape(-1, 1)).flatten()\n","\n","    test_mse = mean_squared_error(y_test_rescaled, test_predictions_rescaled)\n","    test_rmse = np.sqrt(test_mse)\n","    test_mae = mean_absolute_error(y_test_rescaled, test_predictions_rescaled)\n","\n","print(f\"Test Metrics:\")\n","print(f\"  Test RMSE: {test_rmse:.4f}\")\n","print(f\"  Test MAE: {test_mae:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dwbfr8nVR-Mi","executionInfo":{"status":"ok","timestamp":1752829150223,"user_tz":-345,"elapsed":4458,"user":{"displayName":"Shaswot Poudyal","userId":"10950154078121976776"}},"outputId":"e73f7cd4-c700-4dae-893b-888c8b165e48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Training Loss: 0.9413\n","Epoch [2/20], Training Loss: 0.9202\n","Epoch [3/20], Training Loss: 0.9145\n","Epoch [4/20], Training Loss: 0.9122\n","Epoch [5/20], Training Loss: 0.9101\n","Epoch [6/20], Training Loss: 0.9082\n","Epoch [7/20], Training Loss: 0.9065\n","Epoch [8/20], Training Loss: 0.9048\n","Epoch [9/20], Training Loss: 0.9033\n","Epoch [10/20], Training Loss: 0.9018\n","Epoch [11/20], Training Loss: 0.9004\n","Epoch [12/20], Training Loss: 0.8990\n","Epoch [13/20], Training Loss: 0.8977\n","Epoch [14/20], Training Loss: 0.8964\n","Epoch [15/20], Training Loss: 0.8950\n","Epoch [16/20], Training Loss: 0.8937\n","Epoch [17/20], Training Loss: 0.8924\n","Epoch [18/20], Training Loss: 0.8910\n","Epoch [19/20], Training Loss: 0.8896\n","Epoch [20/20], Training Loss: 0.8882\n","Test Metrics:\n","  Test RMSE: 4.0655\n","  Test MAE: 2.8418\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lQn4NfsdUL2H"},"execution_count":null,"outputs":[]}]}